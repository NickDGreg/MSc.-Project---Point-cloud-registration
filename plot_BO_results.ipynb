{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot results of Bayesian optimisation registration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots are based on tutorial from Randy Olsen\n",
    "http://www.randalolson.com/2014/06/28/how-to-make-beautiful-data-visualizations-in-python-with-matplotlib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    for k,v in results.items():\n",
    "        print(k)\n",
    "        for i,j in v.items():\n",
    "            print(i,j)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max(error_lists):\n",
    "    max_values = [max(error_list) for error_list in error_lists]\n",
    "    return max(max_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Read in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_file = 'results/all_sparse_maxRot_prevbest_past_chck_reg.json'\n",
    "full_simple_file = 'results/all_full_maxRot_simple_reg.json'\n",
    "full_prevbest_file = 'results/all_full_maxRot_prevbest_pastChks_reg.json'\n",
    "full_ltd_file = 'results/all_full_maxRot_ltd_pastChks_reg.json'\n",
    "sparse_simple_file = 'results/all_sparse_maxRot_simple_reg.json'\n",
    "sparse_prevbest_file = 'results/all_sparse_maxRot_prevbest_pastChks_reg.json'\n",
    "sparse_ltd_file = 'results/all_sparse_maxRot_ltd_pastChks_reg.json'\n",
    "\n",
    "full_simple_results = None\n",
    "full_prevbest_results = None \n",
    "full_ltd_results = None \n",
    "sparse_simple_results = None\n",
    "sparse_prevbest_results = None\n",
    "sparse_ltd_results = None\n",
    "\n",
    "results = [full_simple_file, full_prevbest_file, full_ltd_file,\n",
    "           sparse_simple_file, sparse_prevbest_file, sparse_ltd_file]\n",
    "method_results = [full_simple_results, full_prevbest_results, full_ltd_results,\n",
    "                  sparse_simple_results, sparse_prevbest_results, sparse_ltd_results]\n",
    "traj_indices = [str(x) for x in range(10)]\n",
    "\n",
    "for i in range(len(results)):\n",
    "    with open(results[i]) as fh:\n",
    "        method_results[i] = json.load(fh)\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store names\n",
    "Used to retrieve from result dictionaries and plot legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_types = ['GT_error', 'bo_opt_error', 'comp_time', 'diff_to_GT_error',\n",
    "               'global_opt_error']\n",
    "method_names = ['full_simple', 'full_prevbest', 'full_ltd',\n",
    "                'sparse_simple', 'sparse_prevbest', 'sparse_ltd']\n",
    "full_methods = ['full_simple', 'full_prevbest', 'full_ltd']\n",
    "sparse_methods = ['sparse_simple', 'sparse_prevbest', 'sparse_ltd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User defined registration methods and errors to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select methods to compare\n",
    "full_simple = True\n",
    "full_prevbest = False \n",
    "full_ltd = False\n",
    "sparse_simple = True\n",
    "sparse_prevbest = True\n",
    "sparse_ltd = True\n",
    "\n",
    "#select errors to compare\n",
    "GT_error = True \n",
    "bo_opt_error = False \n",
    "diff_to_GT_error = False \n",
    "global_opt_error = True \n",
    "comp_time = False \n",
    "\n",
    "method_selectors = [full_simple, full_prevbest, full_ltd,\n",
    "                    sparse_simple, sparse_prevbest, sparse_ltd]\n",
    "error_selectors = [GT_error, bo_opt_error, comp_time, diff_to_GT_error,\n",
    "               global_opt_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_method_results = [r for r, s in zip(method_results, method_selectors) if s]\n",
    "selected_methods = [m for m, s in zip(method_names, method_selectors) if s]\n",
    "selected_errors = [e for e, s in zip(error_types, error_selectors) if s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "# for error_type in selected_errors:\n",
    "#     all_data[error_type] = [[method_result[idx][error_type] for idx in traj_indices] for method_result in selected_method_results]\n",
    "\n",
    "num_results = len(selected_methods)\n",
    "#avoid selecting ground truth error multiple times from different methods \n",
    "#as its always the same \n",
    "num_GT_results = 0\n",
    "sparse_GT_added = False\n",
    "full_GT_added = False\n",
    "for error_type in selected_errors:\n",
    "    all_data[error_type] = []\n",
    "    for idx, method_result in enumerate(selected_method_results):\n",
    "        if error_type == 'GT_error':\n",
    "                if sparse_GT_added and selected_methods[idx] in sparse_methods:\n",
    "                    continue\n",
    "                elif not sparse_GT_added and selected_methods[idx] in sparse_methods:\n",
    "                    all_data[error_type].append([method_result[idx][error_type] for idx in traj_indices])\n",
    "                    sparse_GT_added = True\n",
    "                    num_GT_results += 1\n",
    "                elif full_GT_added and selected_methods[idx] in full_methods:\n",
    "                    continue\n",
    "                elif not full_GT_added and  selected_methods[idx] in full_methods:\n",
    "                    all_data[error_type].append([method_result[idx][error_type] for idx in traj_indices])\n",
    "                    full_GT_added = True\n",
    "                    num_GT_results += 1\n",
    "        else:\n",
    "            all_data[error_type].append([method_result[idx][error_type] for idx in traj_indices])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot selected registration methods and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_present = 0\n",
    "if num_GT_results: GT_present = 1\n",
    "num_bars_per_subset = ((len(all_data) - (1 * GT_present)) * num_results) + num_GT_results\n",
    "num_bars_per_subset += 1 #creates space between each sub trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# These are the \"Tableau 20\" colors as RGB.    \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "\n",
    "patterns = [None, '-',  '.', '\\\\', '*','x', 'o','+', 'O']\n",
    "\n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)    \n",
    "\n",
    "# You typically want your plot to be ~1.33x wider than tall. This plot is a rare    \n",
    "# exception because of the number of lines being plotted on it.    \n",
    "# Common sizes: (10, 7.5) and (12, 9)    \n",
    "plt.figure(figsize=(10, 7.5))    \n",
    "  \n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.    \n",
    "ax = plt.subplot(111)    \n",
    "ax.spines[\"top\"].set_visible(False)    \n",
    "ax.spines[\"bottom\"].set_visible(False)    \n",
    "ax.spines[\"right\"].set_visible(False)    \n",
    "ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.    \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.    \n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left()  \n",
    "\n",
    "N = len(traj_indices)\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "# num_bars_per_subset = (len(all_data) * num_results) + num_GT_results\n",
    "margin = 0.03\n",
    "width = (1-(num_bars_per_subset * margin)) / num_bars_per_subset      # the width of the bars\n",
    "\n",
    "\n",
    "# Limit the range of the plot to only where the data is.    \n",
    "# Avoid unnecessary whitespace.    \n",
    "max_X = len(traj_indices) + 1\n",
    "max_Y = 0\n",
    "for error, results in all_data.items():\n",
    "    max_found = get_max(results)\n",
    "    if max_found > max_Y:\n",
    "        max_Y = max_found\n",
    "max_Y = ceil(max_Y) + 1\n",
    "max_Y = 130\n",
    "plt.ylim(0, max_Y)    \n",
    "# plt.xlim(1968, 2014)    \n",
    "  \n",
    "plt.xticks(range(1,max_X), [str(x) for x in range(1, max_X)], fontsize=14)\n",
    "tick_steps = ceil((max_Y + 1) / 10)\n",
    "dash_steps = ceil((max_Y + 1) / 5)\n",
    "#plot y markers\n",
    "plt.yticks(range(0, max_Y+1, tick_steps), [str(x) for x in range(0, max_Y+1, tick_steps)], fontsize=14) \n",
    "#plot tick lines across plot\n",
    "for y in range(0, max_Y+1, dash_steps):    \n",
    "    plt.plot(range(0, max_X), [y] * len(range(0, max_X)), \"--\", lw=0.5, color=\"black\", alpha=0.3)    \n",
    "    \n",
    "# Remove the tick marks; they are unnecessary with the tick lines we just plotted.    \n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",    \n",
    "                labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")    \n",
    "\n",
    "\n",
    "full_result_set_width = num_results * (width + margin) \n",
    "GT_result_set_width = num_GT_results * (width + margin)\n",
    "prev_result_set = 0\n",
    "for rank, name in enumerate(selected_errors):\n",
    "    for sub, data in enumerate(all_data[name]):\n",
    "        idxs = np.arange(N) + (rank * prev_result_set) + (sub * (margin + width))\n",
    "        labelname = name + '_' + selected_methods[sub]\n",
    "        if len(selected_errors) > 1:\n",
    "            ax.bar(idxs, all_data[name][sub], width, color=tableau20[rank], \n",
    "                   label=labelname, hatch=patterns[sub])\n",
    "        else:\n",
    "            ax.bar(idxs, all_data[name][sub], width, color=tableau20[sub], \n",
    "                   label=labelname)\n",
    "    if name == 'GT_error':\n",
    "        prev_result_set = GT_result_set_width\n",
    "    else:\n",
    "        prev_result_set = full_result_set_width\n",
    "            \n",
    "# add some text for labels, title and axes ticks\n",
    "if 'comp_time' in selected_errors:\n",
    "    ax.set_ylabel('Time (s)')\n",
    "else:\n",
    "    ax.set_ylabel('Error (mm)')\n",
    "ax.set_xlabel('Trajectory subset')\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.003, 1.0), loc=2, borderaxespad=0.05)\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=3, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
